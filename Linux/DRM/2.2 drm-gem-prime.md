# drm: base prime/dma-buf support
```
From: Dave Airlie <airlied@redhat.com>

This adds the basic drm dma-buf interface layer, called PRIME,

The main APIs exposed to userspace allow translating a 32-bit object handle
to a file descriptor, and a file descriptor to a 32-bit object handle.

The flags value is currently limited to O_CLOEXEC.

Acknowledgements:
Daniel Vetter: lots of review
Rob Clark: cleaned up lots of the internals and did lifetime review.

This is what I intend to send to Linus to form the basis for prime work
in the drivers.

Signed-off-by: Dave Airlie <airlied@redhat.com>
```

首先在drm_open时，检查DRIVER_PRIME feature,并初始化priv->prime结构体，
`drm_prime_init_file_private(&priv->prime);`
其次，增加两个IOCTL，暴露给用户空间
``` C
DRM_IOCTL_DEF(DRM_IOCTL_PRIME_HANDLE_TO_FD, drm_prime_handle_to_fd_ioctl, DRM_AUTH|DRM_UNLOCKED),
DRM_IOCTL_DEF(DRM_IOCTL_PRIME_FD_TO_HANDLE, drm_prime_fd_to_handle_ioctl, DRM_AUTH|DRM_UNLOCKED)
```
对于drm_gem_prime_handle_to_fd, 需要将device的BO export出去，所以当传入一个handle之后，通过per device 变量handle首先索引到需要export的BO，
``` C
int drm_gem_prime_handle_to_fd(struct drm_device *dev,
        struct drm_file *file_priv, uint32_t handle, uint32_t flags,
        int *prime_fd)
{
    struct drm_gem_object *obj;
    obj = drm_gem_object_lookup(dev, file_priv, handle);
    if (!obj)
        return -ENOENT;
  
    /* 检查import_attach,不允许已经import的bo再次被export */
    if (obj->import_attach) {
        drm_gem_object_unreference_unlocked(obj);
        return -EINVAL;
    }
    
    /* 检查export_dma_buf, 如果已经被export则直接获取prime_fd */
    if (obj->export_dma_buf) {
        get_file(obj->export_dma_buf->file);
        *prime_fd = dma_buf_fd(obj->export_dma_buf, flags);
        drm_gem_object_unreference_unlocked(obj);
    } else {
     /* 否则,执行export流程, 调用gem_prime_export赋值export_dma_buf*/
        obj->export_dma_buf =
                dev->driver->gem_prime_export(dev, obj, flags);
        if (IS_ERR_OR_NULL(obj->export_dma_buf)) {
            drm_gem_object_unreference_unlocked(obj);
            return PTR_ERR(obj->export_dma_buf);
        }
        *prime_fd = dma_buf_fd(obj->export_dma_buf, flags);
    }
    return 0;
}
EXPORT_SYMBOL(drm_gem_prime_handle_to_fd);
```

相反的接口drm_gem_prime_fd_to_handle,则是将BO import进来，无论是另一个device还是同一device。
``` C
int drm_gem_prime_fd_to_handle(struct drm_device *dev,
        struct drm_file *file_priv, int prime_fd, uint32_t *handle)
{
    struct dma_buf *dma_buf;
    struct drm_gem_object *obj;
    int ret;

    /* 从传入的prime_fd转换到dma_buf */
    dma_buf = dma_buf_get(prime_fd);
    if (IS_ERR(dma_buf))
        return PTR_ERR(dma_buf);
    /* 从当前device的prime链表中查找dma_buf，成功则直接返回 */
    ret = drm_prime_lookup_fd_handle_mapping(&file_priv->prime,
            dma_buf, handle);
    if (!ret) {
        dma_buf_put(dma_buf);
        return 0;
    }
  
    /* 否则，dma_buf属于另外device，调用gem_prime_import导入该dma_buf为obj */
    obj = dev->driver->gem_prime_import(dev, dma_buf);
    if (IS_ERR_OR_NULL(obj)) {
        ret = PTR_ERR(obj);
        goto fail_put;
    }
    /* 为导入的obj创建gem接口 */
    ret = drm_gem_handle_create(file_priv, obj, handle);
    drm_gem_object_unreference_unlocked(obj);
    if (ret)
        goto fail_put;
    /* 将导入的dma_buf接入到该device的prime链表 */
    ret = drm_prime_insert_fd_handle_mapping(&file_priv->prime,
            dma_buf, *handle);
    if (ret)
        goto fail;
  
    return 0;

fail:
    drm_gem_object_handle_unreference_unlocked(obj);
fail_put:
    dma_buf_put(dma_buf);
    return ret;
}
EXPORT_SYMBOL(drm_gem_prime_fd_to_handle);
```


# PRIME Helper Functions

- **gem_prime_get_sg_table**: provide a scatter/gather table of pinned pages
-  **gem_prime_vmap**: vmap a buffer exported by your driver

该助手程序从一组页面创建一个 sg 表对象，驱动程序负责将这些页面映射到导入器的地址空间，以供 dma_buf 本身使用。
``` C
struct sg_table *drm_prime_pages_to_sg(struct page **pages, int nr_pages)
{
    struct sg_table *sg = NULL;
    struct scatterlist *iter;
    int i;
    int ret;
  
    sg = kzalloc(sizeof(struct sg_table), GFP_KERNEL);
    if (!sg)
        goto out;
  
    ret = sg_alloc_table(sg, nr_pages, GFP_KERNEL);
    if (ret)
        goto out;

    for_each_sg(sg->sgl, iter, nr_pages, i)
        sg_set_page(iter, pages[i], PAGE_SIZE, 0);
  
    return sg;
out:
    kfree(sg);
    return NULL;
}
EXPORT_SYMBOL(drm_prime_pages_to_sg);
```


drm_gem_dmabuf_export -> drm_gem_dmabuf_export -> dma_buf_export

``` C
struct dma_buf *drm_gem_dmabuf_export(struct drm_device *dev,
                      struct dma_buf_export_info *exp_info)
{
    struct drm_gem_object *obj = exp_info->priv;
    struct dma_buf *dma_buf;
  
    dma_buf = dma_buf_export(exp_info);
    if (IS_ERR(dma_buf))
        return dma_buf;
  
    drm_dev_get(dev);
    drm_gem_object_get(obj);
    dma_buf->file->f_mapping = obj->dev->anon_inode->i_mapping;
  
    return dma_buf;
}
EXPORT_SYMBOL(drm_gem_dmabuf_export);
```

``` C
struct dma_buf *drm_gem_prime_export(struct drm_gem_object *obj,
                     int flags)
{
    struct drm_device *dev = obj->dev;
    struct dma_buf_export_info exp_info = {
        .exp_name = KBUILD_MODNAME, /* white lie for debug */
        .owner = dev->driver->fops->owner,
        .ops = &drm_gem_prime_dmabuf_ops,
        .size = obj->size,
        .flags = flags,
        .priv = obj,
        .resv = obj->resv,
    };
  
    return drm_gem_dmabuf_export(dev, &exp_info);
}
EXPORT_SYMBOL(drm_gem_prime_export);
```

amdgpu_gem_prime_import -> drm_gem_prime_import -> dma_buf_attach -> amdgpu_gem_prime_import_sg_table
Import BO代表该设备引入其他的BO，该操作应该增加BO的引用计数，保证BO不会被释放。
``` C
struct drm_gem_object *drm_gem_prime_import_dev(struct drm_device *dev,
                        struct dma_buf *dma_buf,
                        struct device *attach_dev)
{
    struct dma_buf_attachment *attach;
    struct sg_table *sgt;
    struct drm_gem_object *obj;
    int ret;
  
    if (dma_buf->ops == &drm_gem_prime_dmabuf_ops) {
        obj = dma_buf->priv;
        if (obj->dev == dev) {
            /*
             * Importing dmabuf exported from our own gem increases
             * refcount on gem itself instead of f_count of dmabuf.
             */
            drm_gem_object_get(obj);
            return obj;
        }
    }
  
    if (!dev->driver->gem_prime_import_sg_table)
        return ERR_PTR(-EINVAL);
  
    attach = dma_buf_attach(dma_buf, attach_dev);
    if (IS_ERR(attach))
        return ERR_CAST(attach);
  
    get_dma_buf(dma_buf);
    sgt = dma_buf_map_attachment_unlocked(attach, DMA_BIDIRECTIONAL);
    if (IS_ERR(sgt)) {
        ret = PTR_ERR(sgt);
        goto fail_detach;
    }
  
    obj = dev->driver->gem_prime_import_sg_table(dev, attach, sgt);
    if (IS_ERR(obj)) {
        ret = PTR_ERR(obj);
        goto fail_unmap;
    }
  
    obj->import_attach = attach;
    obj->resv = dma_buf->resv;
    return obj;
  
fail_unmap:
    dma_buf_unmap_attachment_unlocked(attach, sgt, DMA_BIDIRECTIONAL);
fail_detach:
    dma_buf_detach(dma_buf, attach);
    dma_buf_put(dma_buf);
  
    return ERR_PTR(ret);
}
EXPORT_SYMBOL(drm_gem_prime_import_dev);
```

``` C
struct drm_gem_object *
amdgpu_gem_prime_import_sg_table(struct drm_device *dev,
                 struct dma_buf_attachment *attach,
                 struct sg_table *sg)
{
    struct dma_resv *resv = attach->dmabuf->resv;
    struct amdgpu_device *adev = drm_to_adev(dev);
    struct amdgpu_bo *bo;
    struct amdgpu_bo_param bp;
    int ret;

    memset(&bp, 0, sizeof(bp));
    bp.size = attach->dmabuf->size;
    bp.byte_align = PAGE_SIZE;
    bp.domain = AMDGPU_GEM_DOMAIN_CPU;
    bp.flags = 0;
    bp.type = ttm_bo_type_sg;
    bp.resv = resv;
    bp.bo_ptr_size = sizeof(struct amdgpu_bo);
    dma_resv_lock(resv, NULL);
    ret = amdgpu_bo_create(adev, &bp, &bo);
    if (ret)
        goto error;
  
    bo->tbo.sg = sg;
    bo->tbo.ttm->sg = sg;
    bo->allowed_domains = AMDGPU_GEM_DOMAIN_GTT;
    bo->preferred_domains = AMDGPU_GEM_DOMAIN_GTT;
    dma_resv_unlock(resv);
    return &bo->tbo.base;
  
error:
    dma_resv_unlock(resv);
    return ERR_PTR(ret);
}
```